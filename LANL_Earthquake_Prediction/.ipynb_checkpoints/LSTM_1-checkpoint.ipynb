{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"precision\",16)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Config(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lr = 0.001\n",
    "        self.num_layers = 1\n",
    "        self.hidden_size = 100\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        self.num_epochs = 1000\n",
    "        self.batch_size = 50\n",
    "        self.step_size = 5\n",
    "        self.reuse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(object):\n",
    "    def __init__(self,scope,feed,config):\n",
    "        self.config = config\n",
    "        with tf.variable_scope(scope):\n",
    "            self.feed = feed\n",
    "            self.inputs = feed.input_data\n",
    "            self.targets = feed.target_data\n",
    "            self._build_graph()\n",
    "    \n",
    "    def _build_graph(self):\n",
    "        #self._init_placeholders()\n",
    "        self._build_model()\n",
    "        self._setup_training()\n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        self.input_ph = tf.placeholder(\n",
    "            tf.float32, \n",
    "            [None, self.config.step_size, self.config.input_size],\n",
    "            name=\"input_ph\"\n",
    "        )\n",
    "        self.labels_ph = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [None, self.config.step_size, self.config.output_size],\n",
    "            name=\"labels_ph\"\n",
    "        )\n",
    "        \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope(\"model\", reuse=self.config.reuse):\n",
    "            lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "                self.config.hidden_size,\n",
    "                activation=tf.nn.relu,\n",
    "                state_is_tuple=True\n",
    "            )\n",
    "            \n",
    "            batch_size = tf.shape(self.inputs)[0]\n",
    "            step_size = tf.shape(self.inputs)[1]\n",
    "            \n",
    "            self.state_in = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "            \n",
    "            self.model, self.state = tf.nn.dynamic_rnn(\n",
    "                lstm_cell,\n",
    "                self.inputs,\n",
    "                initial_state=self.state_in,\n",
    "                time_major=False\n",
    "            )\n",
    "            \n",
    "            c,h = self.state\n",
    "            self.state_out = (c,h)\n",
    "            self.model = tf.reshape(self.model, shape=[-1,self.config.hidden_size])\n",
    "            \n",
    "            weights = tf.Variable(tf.random_uniform(\n",
    "                [self.config.hidden_size, self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            biases = tf.Variable(tf.random_uniform(\n",
    "                [self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            self.model = tf.nn.xw_plus_b(self.model, weights, biases, name=\"model\")\n",
    "            self.model = tf.reshape(self.model, shape=[batch_size, step_size, self.config.output_size])\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        self.loss = tf.reduce_sum(tf.square(self.model - self.targets))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.config.lr)\n",
    "        self.training = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.data.python.ops import sliding\n",
    "\n",
    "def batch_producer(raw_data, raw_targets, batch_size, step_size):\n",
    "    raw_data_tensor = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.float32)\n",
    "    raw_targets_tensor = tf.convert_to_tensor(raw_targets, name=\"raw_targets\", dtype=tf.float32)\n",
    "    \n",
    "    data_len = tf.shape(raw_data_tensor)[0]\n",
    "    batched_len = data_len // batch_size\n",
    "    data = tf.reshape(raw_data_tensor[0:batch_size*batched_len],\n",
    "                     [batch_size, batched_len])\n",
    "    targets = tf.reshape(raw_targets_tensor[0:batch_size*batched_len],\n",
    "                        [batch_size, batched_len])\n",
    "\n",
    "    data = tf.data.Dataset.from_tensor_slices(tf.transpose(data))\n",
    "    targets = tf.data.Dataset.from_tensor_slices(tf.transpose(targets))\n",
    "    window = step_size\n",
    "    stride = 1\n",
    "\n",
    "    data = data.apply(sliding.sliding_window_batch(window,stride))\n",
    "    targets = targets.apply(sliding.sliding_window_batch(window,stride))\n",
    "\n",
    "    data_iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n",
    "    target_iterator = tf.data.Iterator.from_structure(targets.output_types, targets.output_shapes)\n",
    "    next_element = data_iterator.get_next()\n",
    "    target_element = target_iterator.get_next()\n",
    "\n",
    "    next_batch = tf.expand_dims(next_element,0)\n",
    "    next_batch = tf.transpose(next_batch)\n",
    "    next_targets = tf.expand_dims(target_element,0)\n",
    "    next_targets = tf.transpose(next_targets)\n",
    "\n",
    "    init_op = [data_iterator.make_initializer(data),target_iterator.make_initializer(targets)]\n",
    "    return next_batch, next_targets, init_op\n",
    "    \n",
    "class Data_Feed(object):\n",
    "    def __init__(self, data, targets, batch_size, step_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        #print(len(data) // batch_size)\n",
    "        self.epoch_size = ((len(data) // batch_size)-1) // step_size\n",
    "        print(self.epoch_size)\n",
    "        self.input_data, self.target_data, self.init_op = \\\n",
    "            batch_producer(data,targets, batch_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, training_targets, config):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    training_feed = Data_Feed(training_data, training_targets, config.batch_size, config.step_size)\n",
    "    model = LSTM_Model('model', training_feed, config)\n",
    "    \n",
    "    \n",
    "    print_interval = 1\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run([init_op])\n",
    "        sess.run([training_feed.init_op])\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for epoch in range(config.num_epochs):\n",
    "            lstm_state = np.zeros((2, config.batch_size, config.hidden_size))\n",
    "            \n",
    "            try:\n",
    "                for step in range(training_feed.epoch_size):\n",
    "                    if step % print_interval != 0:\n",
    "                        loss, _,  lstm_state = sess.run(\\\n",
    "                            [model.loss, model.training, model.state],\n",
    "                            feed_dict={model.state_in[0] : lstm_state[0],\n",
    "                                      model.state_in[1] : lstm_state[1]})\n",
    "                    else:\n",
    "                        loss, _,  lstm_state = sess.run(\\\n",
    "                            [model.loss, model.training, model.state],\n",
    "                            feed_dict={model.state_in[0] : lstm_state[0],\n",
    "                                      model.state_in[1] : lstm_state[1]})\n",
    "                        print(\"Epoch {}, Step {}, Loss : {}\".format(\n",
    "                            epoch, step, loss\n",
    "                        ))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of epoch...\")\n",
    "                sess.run([training_feed.init_op])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 54s, sys: 28.6 s, total: 3min 23s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"./train/train.csv\", dtype={'acoustic_data':np.int16, 'time_to_failure':np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "signal_train, fail_train = data['acoustic_data'].values[41:100041], \\\n",
    "                            data['time_to_failure'].values[41:100041]\n",
    "signal_test, fail_test = data['acoustic_data'].values[100041:120041], \\\n",
    "                            data['time_to_failure'].values[100041:120041]\n",
    "\n",
    "print(len(signal_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "Epoch 0, Step 0, Loss : 497.47186279296875\n",
      "Epoch 0, Step 50, Loss : nan\n",
      "Epoch 0, Step 100, Loss : nan\n",
      "Epoch 0, Step 150, Loss : nan\n",
      "Epoch 0, Step 200, Loss : nan\n",
      "Epoch 0, Step 250, Loss : nan\n",
      "Epoch 0, Step 300, Loss : nan\n",
      "Epoch 0, Step 350, Loss : nan\n",
      "Epoch 1, Step 0, Loss : nan\n",
      "Epoch 1, Step 50, Loss : nan\n",
      "Epoch 1, Step 100, Loss : nan\n",
      "Epoch 1, Step 150, Loss : nan\n",
      "Epoch 1, Step 200, Loss : nan\n",
      "Epoch 1, Step 250, Loss : nan\n",
      "Epoch 1, Step 300, Loss : nan\n",
      "Epoch 1, Step 350, Loss : nan\n",
      "Epoch 2, Step 0, Loss : nan\n",
      "Epoch 2, Step 50, Loss : nan\n",
      "Epoch 2, Step 100, Loss : nan\n",
      "Epoch 2, Step 150, Loss : nan\n",
      "Epoch 2, Step 200, Loss : nan\n",
      "Epoch 2, Step 250, Loss : nan\n",
      "Epoch 2, Step 300, Loss : nan\n",
      "Epoch 2, Step 350, Loss : nan\n",
      "Epoch 3, Step 0, Loss : nan\n",
      "Epoch 3, Step 50, Loss : nan\n",
      "Epoch 3, Step 100, Loss : nan\n",
      "Epoch 3, Step 150, Loss : nan\n",
      "Epoch 3, Step 200, Loss : nan\n",
      "Epoch 3, Step 250, Loss : nan\n",
      "Epoch 3, Step 300, Loss : nan\n",
      "Epoch 3, Step 350, Loss : nan\n",
      "Epoch 4, Step 0, Loss : nan\n",
      "Epoch 4, Step 50, Loss : nan\n",
      "Epoch 4, Step 100, Loss : nan\n",
      "Epoch 4, Step 150, Loss : nan\n",
      "Epoch 4, Step 200, Loss : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-814635c949dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-9304ae7e6192>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_data, training_targets, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                             feed_dict={model.state_in[0] : lstm_state[0],\n\u001b[0;32m---> 29\u001b[0;31m                                       model.state_in[1] : lstm_state[1]})\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         loss, _,  lstm_state = sess.run(\\\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config =  LSTM_Config()\n",
    "#feed = Data_Feed(signal_train, fail_train, config.batch_size, config.step_size)\n",
    "ct = 0\n",
    "\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(feed_test.init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            val = sess.run(feed_test.input_data)\n",
    "            print(val)\n",
    "            print(ct)\n",
    "            ct += 1\n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "            break\n",
    "\"\"\"\n",
    "train(signal_train, fail_train, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  6  3  4  2  3 10  6  8 11 11 11  2  9  7  3  8  7  4  4]\n",
      "[[ 3  6  3  4  2  3]\n",
      " [10  6  8 11 11 11]\n",
      " [ 2  9  7  3  8  7]]\n",
      "(3, 6)\n",
      "[[1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]\n",
      " [1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]\n",
      " [1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]]\n"
     ]
    }
   ],
   "source": [
    "test = signal_train[0:20]\n",
    "y = fail_train[0:20]\n",
    "batch_size = 3\n",
    "step_size = 2\n",
    "\n",
    "data_len = len(test)\n",
    "batched_len = data_len // batch_size\n",
    "epoch_size = (batched_len-1) // step_size\n",
    "\n",
    "training_data = np.reshape(test[0:batched_len*batch_size],\n",
    "                          [batch_size, batched_len])\n",
    "training_label = np.reshape(y[0:batched_len*batch_size],\n",
    "                           [batch_size, batched_len])\n",
    "\n",
    "\n",
    "\n",
    "print(test)\n",
    "print(training_data)\n",
    "print(np.shape(training_data))\n",
    "print(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1, 20, 1)\n",
      "[[[ 3]\n",
      "  [ 6]\n",
      "  [ 3]\n",
      "  [ 4]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [10]\n",
      "  [ 6]\n",
      "  [ 8]\n",
      "  [11]\n",
      "  [11]\n",
      "  [11]\n",
      "  [ 2]\n",
      "  [ 9]\n",
      "  [ 7]\n",
      "  [ 3]\n",
      "  [ 8]\n",
      "  [ 7]\n",
      "  [ 4]\n",
      "  [ 4]]]\n"
     ]
    }
   ],
   "source": [
    "test = signal_train[0:20]\n",
    "num_periods = 20\n",
    "x_data = test[0:(len(test)-(len(test) % num_periods))]\n",
    "x_batches = x_data.reshape(-1,20,1)\n",
    "print(len(test) % num_periods)\n",
    "print(x_batches.shape)\n",
    "print(x_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorSliceDataset' object has no attribute 'window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-e0adc46fbcba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#data = data.apply(sliding.sliding_window_batch(window,stride))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msliding_window_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute 'window'"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.data.python.ops import sliding\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(training_data.T)\n",
    "targets = tf.data.Dataset.from_tensor_slices(training_label.T)\n",
    "window = 2\n",
    "stride = 1\n",
    "\n",
    "data = data.apply(sliding.sliding_window_batch(window,stride))\n",
    "targets = targets.apply(sliding.sliding_window_batch(window,stride))\n",
    "\n",
    "data_iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n",
    "target_iterator = tf.data.Iterator.from_structure(targets.output_types, targets.output_shapes)\n",
    "next_element = data_iterator.get_next()\n",
    "target_element = target_iterator.get_next()\n",
    "\n",
    "next_batch = tf.expand_dims(next_element,0)\n",
    "next_batch = tf.transpose(next_batch)\n",
    "next_targets = tf.expand_dims(target_element,0)\n",
    "next_targets = tf.transpose(next_targets)\n",
    "\n",
    "init_op = [data_iterator.make_initializer(data),target_iterator.make_initializer(targets)]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            batch = sess.run(next_batch)\n",
    "            tar = sess.run(next_targets)\n",
    "            print(batch)\n",
    "            print(tar)\n",
    "            print(np.shape(batch))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
