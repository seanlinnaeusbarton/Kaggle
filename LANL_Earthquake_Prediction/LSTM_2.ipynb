{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"precision\",16)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Config(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lr = 0.0001\n",
    "        self.num_layers = 1\n",
    "        self.hidden_size = 100\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        self.num_epochs = 1000\n",
    "        self.batch_size = 50\n",
    "        self.step_size = 5\n",
    "        self.reuse = False\n",
    "        self.print_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(object):\n",
    "    def __init__(self,scope,config):\n",
    "        self.config = config\n",
    "        with tf.variable_scope(scope):\n",
    "            self._build_graph()\n",
    "    \n",
    "    def _build_graph(self):\n",
    "        self._init_placeholders()\n",
    "        self._build_model()\n",
    "        self._setup_training()\n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        self.input_ph = tf.placeholder(\n",
    "            tf.float32, \n",
    "            [None, self.config.step_size, self.config.input_size],\n",
    "            name=\"input_ph\"\n",
    "        )\n",
    "        self.targets_ph = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [None, self.config.output_size],\n",
    "            name=\"targets_ph\"\n",
    "        )\n",
    "        \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope(\"model\", reuse=self.config.reuse):\n",
    "            lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "                self.config.hidden_size,\n",
    "                activation=tf.nn.relu,\n",
    "                state_is_tuple=True\n",
    "            )\n",
    "            \n",
    "            batch_size = tf.shape(self.input_ph)[0]\n",
    "            step_size = tf.shape(self.input_ph)[1]\n",
    "            \n",
    "            self.state_in = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "            \n",
    "            self.model, self.state = tf.nn.dynamic_rnn(\n",
    "                lstm_cell,\n",
    "                self.input_ph,\n",
    "                initial_state=self.state_in,\n",
    "                time_major=False\n",
    "            )\n",
    "            \n",
    "            c,h = self.state\n",
    "            self.state_out = (c,h)\n",
    "            self.model = tf.reshape(self.model, shape=[-1,self.config.hidden_size])\n",
    "            \n",
    "            weights = tf.Variable(tf.random_uniform(\n",
    "                [self.config.hidden_size, self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            biases = tf.Variable(tf.random_uniform(\n",
    "                [self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            self.model = tf.nn.xw_plus_b(self.model, weights, biases, name=\"model\")\n",
    "            self.model = tf.reshape(self.model, shape=[batch_size, step_size, self.config.output_size])\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        self.loss = tf.reduce_sum(tf.square(self.model - self.targets_ph))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.config.lr)\n",
    "        self.training = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"./train/train.csv\", dtype={'acoustic_data':np.int16, 'time_to_failure':np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "signal_train, fail_train = data['acoustic_data'].values[41:100041], \\\n",
    "                            data['time_to_failure'].values[41:100041]\n",
    "next_signal_train = data['acoustic_data'].values[42:100042]\n",
    "signal_test, fail_test = data['acoustic_data'].values[100043:120043], \\\n",
    "                            data['time_to_failure'].values[100043:120043]\n",
    "next_signal_test = data['acoustic_data'].values[100043:120043]\n",
    "\n",
    "print(len(signal_train))\n",
    "print(len(next_signal_train))\n",
    "print(len(signal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (50,) for Tensor 'model/input_ph:0', which has shape '(?, 5, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-902566b7fb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         loss, _, lstm_state = sess.run([model.loss, model.training, model.state],\n\u001b[1;32m---> 50\u001b[1;33m                 feed_dict=training_feed)\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             eval_feed = {\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ALLIES\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ALLIES\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1074\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1076\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1077\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (50,) for Tensor 'model/input_ph:0', which has shape '(?, 5, 1)'"
     ]
    }
   ],
   "source": [
    "config =  LSTM_Config()\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = LSTM_Model('model', config)\n",
    "\n",
    "\n",
    "print_interval = config.print_interval\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "index_in_epoch = 0\n",
    "perm_array = np.arange(signal_train.shape[0])\n",
    "np.random.shuffle(perm_array)\n",
    "\n",
    "def next_batch(batch_size):\n",
    "    global index_in_epoch, signal_train, next_signal_train, perm_array\n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "\n",
    "    if index_in_epoch > signal_train.shape[0]:\n",
    "        np.random.shuffle(perm_array)\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "\n",
    "    end = index_in_epoch\n",
    "    return signal_train[perm_array[start:end]], next_signal_train[perm_array[start:end]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run([init_op])\n",
    "\n",
    "    train_size = signal_train.shape[0]\n",
    "    lstm_state = np.zeros((2, config.batch_size, config.hidden_size))\n",
    "\n",
    "\n",
    "    for iteration in range(int(config.num_epochs*train_size/config.batch_size)):\n",
    "        if index_in_epoch == 0:\n",
    "            lstm_state = np.zeros((2, config.batch_size, config.hidden_size))\n",
    "\n",
    "        signal_batch, target_batch = next_batch(config.batch_size)\n",
    "\n",
    "        training_feed = {\n",
    "            model.input_ph : signal_batch,\n",
    "            model.targets_ph : target_batch,\n",
    "            model.state_in[0] : lstm_state[0],\n",
    "            model.state_in[1] : lstm_state[1]\n",
    "        }\n",
    "\n",
    "        loss, _, lstm_state = sess.run([model.loss, model.training, model.state],\n",
    "                feed_dict=training_feed)\n",
    "        if iteration % int(5*train_size/config.batch_size) == 0:\n",
    "            eval_feed = {\n",
    "                model.input_ph : signal_train,\n",
    "                model.targets_ph : next_signal_train,\n",
    "                model.state_in[0] : lstm_state[0],\n",
    "                model.state_in[1] : lstm_state[1]\n",
    "            }\n",
    "            mse_train = model.loss.eval(feed_dict=eval_feed)\n",
    "\n",
    "            valid_feed = {\n",
    "                model.input_ph : signal_test,\n",
    "                model.targets_ph : next_signal_test,\n",
    "                model.state_in[0] : lstm_state[0],\n",
    "                model.state_in[1] : lstm_state[1]\n",
    "            }\n",
    "            mse_valid = model.loss.eval(feed_dict=valid_feed)\n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
    "                iteration*config.batch_size/train_size, mse_train, mse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
