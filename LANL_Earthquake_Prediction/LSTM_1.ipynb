{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"precision\",16)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Config(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lr = 0.0000001\n",
    "        self.num_layers = 1\n",
    "        self.hidden_size = 100\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        self.num_epochs = 1000\n",
    "        self.batch_size = 50\n",
    "        self.step_size = 5\n",
    "        self.reuse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(object):\n",
    "    def __init__(self,scope,feed,config):\n",
    "        self.config = config\n",
    "        with tf.variable_scope(scope):\n",
    "            self.feed = feed\n",
    "            self.inputs = feed.input_data\n",
    "            self.targets = feed.target_data\n",
    "            self._build_graph()\n",
    "    \n",
    "    def _build_graph(self):\n",
    "        #self._init_placeholders()\n",
    "        self._build_model()\n",
    "        self._setup_training()\n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        self.input_ph = tf.placeholder(\n",
    "            tf.float32, \n",
    "            [None, self.config.step_size, self.config.input_size],\n",
    "            name=\"input_ph\"\n",
    "        )\n",
    "        self.labels_ph = tf.placeholder(\n",
    "            tf.float32,\n",
    "            [None, self.config.step_size, self.config.output_size],\n",
    "            name=\"labels_ph\"\n",
    "        )\n",
    "        \n",
    "    def _build_model(self):\n",
    "        with tf.variable_scope(\"model\", reuse=self.config.reuse):\n",
    "            lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "                self.config.hidden_size,\n",
    "                activation=tf.nn.relu,\n",
    "                state_is_tuple=True\n",
    "            )\n",
    "            \n",
    "            batch_size = tf.shape(self.inputs)[0]\n",
    "            step_size = tf.shape(self.inputs)[1]\n",
    "            \n",
    "            self.state_in = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "            \n",
    "            self.model, self.state = tf.nn.dynamic_rnn(\n",
    "                lstm_cell,\n",
    "                self.inputs,\n",
    "                initial_state=self.state_in,\n",
    "                time_major=False\n",
    "            )\n",
    "            \n",
    "            c,h = self.state\n",
    "            self.state_out = (c,h)\n",
    "            self.model = tf.reshape(self.model, shape=[-1,self.config.hidden_size])\n",
    "            \n",
    "            weights = tf.Variable(tf.random_uniform(\n",
    "                [self.config.hidden_size, self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            biases = tf.Variable(tf.random_uniform(\n",
    "                [self.config.output_size],\n",
    "                minval=-0.05, maxval=0.05\n",
    "            ))\n",
    "            self.model = tf.nn.xw_plus_b(self.model, weights, biases, name=\"model\")\n",
    "            self.model = tf.reshape(self.model, shape=[batch_size, step_size, self.config.output_size])\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        self.loss = tf.reduce_sum(tf.square(self.model - self.targets))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.config.lr)\n",
    "        self.training = self.optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.data.python.ops import sliding\n",
    "\n",
    "def batch_producer(raw_data, raw_targets, batch_size, step_size):\n",
    "    raw_data_tensor = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.float32)\n",
    "    raw_targets_tensor = tf.convert_to_tensor(raw_targets, name=\"raw_targets\", dtype=tf.float32)\n",
    "    \n",
    "    data_len = tf.shape(raw_data_tensor)[0]\n",
    "    batched_len = data_len // batch_size\n",
    "    data = tf.reshape(raw_data_tensor[0:batch_size*batched_len],\n",
    "                     [batch_size, batched_len])\n",
    "    targets = tf.reshape(raw_targets_tensor[0:batch_size*batched_len],\n",
    "                        [batch_size, batched_len])\n",
    "\n",
    "    data = tf.data.Dataset.from_tensor_slices(tf.transpose(data))\n",
    "    targets = tf.data.Dataset.from_tensor_slices(tf.transpose(targets))\n",
    "    window = step_size\n",
    "    stride = 1\n",
    "\n",
    "    data = data.apply(sliding.sliding_window_batch(window,stride))\n",
    "    targets = targets.apply(sliding.sliding_window_batch(window,stride))\n",
    "\n",
    "    data_iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n",
    "    target_iterator = tf.data.Iterator.from_structure(targets.output_types, targets.output_shapes)\n",
    "    next_element = data_iterator.get_next()\n",
    "    target_element = target_iterator.get_next()\n",
    "\n",
    "    next_batch = tf.expand_dims(next_element,0)\n",
    "    next_batch = tf.transpose(next_batch)\n",
    "    next_targets = tf.expand_dims(target_element,0)\n",
    "    next_targets = tf.transpose(next_targets)\n",
    "\n",
    "    init_op = [data_iterator.make_initializer(data),target_iterator.make_initializer(targets)]\n",
    "    return next_batch, next_targets, init_op\n",
    "    \n",
    "class Data_Feed(object):\n",
    "    def __init__(self, data, targets, batch_size, step_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        #print(len(data) // batch_size)\n",
    "        self.epoch_size = ((len(data) // batch_size)-1) // step_size\n",
    "        print(self.epoch_size)\n",
    "        self.input_data, self.target_data, self.init_op = \\\n",
    "            batch_producer(data,targets, batch_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, training_targets, config):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    training_feed = Data_Feed(training_data, training_targets, config.batch_size, config.step_size)\n",
    "    model = LSTM_Model('model', training_feed, config)\n",
    "    \n",
    "    \n",
    "    print_interval = 1\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run([init_op])\n",
    "        sess.run([training_feed.init_op])\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        for epoch in range(config.num_epochs):\n",
    "            lstm_state = np.zeros((2, config.batch_size, config.hidden_size))\n",
    "            \n",
    "            try:\n",
    "                for step in range(training_feed.epoch_size):\n",
    "                    if step % print_interval != 0:\n",
    "                        loss, _,  lstm_state = sess.run(\\\n",
    "                            [model.loss, model.training, model.state],\n",
    "                            feed_dict={model.state_in[0] : lstm_state[0],\n",
    "                                      model.state_in[1] : lstm_state[1]})\n",
    "                    else:\n",
    "                        loss, _,  lstm_state = sess.run(\\\n",
    "                            [model.loss, model.training, model.state],\n",
    "                            feed_dict={model.state_in[0] : lstm_state[0],\n",
    "                                      model.state_in[1] : lstm_state[1]})\n",
    "                        print(\"Epoch {}, Step {}, Loss : {}\".format(\n",
    "                            epoch, step, loss\n",
    "                        ))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of epoch...\")\n",
    "                sess.run([training_feed.init_op])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 54s, sys: 28.6 s, total: 3min 23s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"./train/train.csv\", dtype={'acoustic_data':np.int16, 'time_to_failure':np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "signal_train, fail_train = data['acoustic_data'].values[41:100041], \\\n",
    "                            data['time_to_failure'].values[41:100041]\n",
    "signal_test, fail_test = data['acoustic_data'].values[100041:120041], \\\n",
    "                            data['time_to_failure'].values[100041:120041]\n",
    "\n",
    "print(len(signal_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "Epoch 0, Step 0, Loss : 507.79638671875\n",
      "Epoch 0, Step 1, Loss : 499.79827880859375\n",
      "Epoch 0, Step 2, Loss : 500.9070739746094\n",
      "Epoch 0, Step 3, Loss : 503.0704345703125\n",
      "Epoch 0, Step 4, Loss : 505.3995666503906\n",
      "Epoch 0, Step 5, Loss : 510.5587158203125\n",
      "Epoch 0, Step 6, Loss : 524.435302734375\n",
      "Epoch 0, Step 7, Loss : 529.12451171875\n",
      "Epoch 0, Step 8, Loss : 538.4261474609375\n",
      "Epoch 0, Step 9, Loss : 862.252685546875\n",
      "Epoch 0, Step 10, Loss : 1242.7371826171875\n",
      "Epoch 0, Step 11, Loss : 700.935546875\n",
      "Epoch 0, Step 12, Loss : 768.528564453125\n",
      "Epoch 0, Step 13, Loss : 1030.80908203125\n",
      "Epoch 0, Step 14, Loss : 1506.082275390625\n",
      "Epoch 0, Step 15, Loss : 2107.952880859375\n",
      "Epoch 0, Step 16, Loss : 4606.67724609375\n",
      "Epoch 0, Step 17, Loss : 6082.43603515625\n",
      "Epoch 0, Step 18, Loss : 15231.244140625\n",
      "Epoch 0, Step 19, Loss : 32049.78125\n",
      "Epoch 0, Step 20, Loss : 72505.4765625\n",
      "Epoch 0, Step 21, Loss : 235303.703125\n",
      "Epoch 0, Step 22, Loss : 624580.75\n",
      "Epoch 0, Step 23, Loss : 2084209.125\n",
      "Epoch 0, Step 24, Loss : 4247886.5\n",
      "Epoch 0, Step 25, Loss : 8379604.5\n",
      "Epoch 0, Step 26, Loss : 19004980.0\n",
      "Epoch 0, Step 27, Loss : 48950116.0\n",
      "Epoch 0, Step 28, Loss : 183336320.0\n",
      "Epoch 0, Step 29, Loss : 732556416.0\n",
      "Epoch 0, Step 30, Loss : 2756144128.0\n",
      "Epoch 0, Step 31, Loss : 5142114304.0\n",
      "Epoch 0, Step 32, Loss : 11049169920.0\n",
      "Epoch 0, Step 33, Loss : 42290626560.0\n",
      "Epoch 0, Step 34, Loss : 100416880640.0\n",
      "Epoch 0, Step 35, Loss : 219890515968.0\n",
      "Epoch 0, Step 36, Loss : 1539503030272.0\n",
      "Epoch 0, Step 37, Loss : 622615461888.0\n",
      "Epoch 0, Step 38, Loss : 205306527744.0\n",
      "Epoch 0, Step 39, Loss : 182225108992.0\n",
      "Epoch 0, Step 40, Loss : 130702049280.0\n",
      "Epoch 0, Step 41, Loss : 144139714560.0\n",
      "Epoch 0, Step 42, Loss : 474524549120.0\n",
      "Epoch 0, Step 43, Loss : 2557058220032.0\n",
      "Epoch 0, Step 44, Loss : 3842378825728.0\n",
      "Epoch 0, Step 45, Loss : 4697252954112.0\n",
      "Epoch 0, Step 46, Loss : 8174791294976.0\n",
      "Epoch 0, Step 47, Loss : 13754651639808.0\n",
      "Epoch 0, Step 48, Loss : 102787367043072.0\n",
      "Epoch 0, Step 49, Loss : 161653207334912.0\n",
      "Epoch 0, Step 50, Loss : 17015897063424.0\n",
      "Epoch 0, Step 51, Loss : 280283693711360.0\n",
      "Epoch 0, Step 52, Loss : 600891358969856.0\n",
      "Epoch 0, Step 53, Loss : 1586307247636480.0\n",
      "Epoch 0, Step 54, Loss : 8333623828676608.0\n",
      "Epoch 0, Step 55, Loss : 4.197472397374259e+16\n",
      "Epoch 0, Step 56, Loss : 1.394177565744169e+17\n",
      "Epoch 0, Step 57, Loss : 5.255825353552691e+17\n",
      "Epoch 0, Step 58, Loss : nan\n",
      "Epoch 0, Step 59, Loss : nan\n",
      "Epoch 0, Step 60, Loss : nan\n",
      "Epoch 0, Step 61, Loss : nan\n",
      "Epoch 0, Step 62, Loss : nan\n",
      "Epoch 0, Step 63, Loss : nan\n",
      "Epoch 0, Step 64, Loss : nan\n",
      "Epoch 0, Step 65, Loss : nan\n",
      "Epoch 0, Step 66, Loss : nan\n",
      "Epoch 0, Step 67, Loss : nan\n",
      "Epoch 0, Step 68, Loss : nan\n",
      "Epoch 0, Step 69, Loss : nan\n",
      "Epoch 0, Step 70, Loss : nan\n",
      "Epoch 0, Step 71, Loss : nan\n",
      "Epoch 0, Step 72, Loss : nan\n",
      "Epoch 0, Step 73, Loss : nan\n",
      "Epoch 0, Step 74, Loss : nan\n",
      "Epoch 0, Step 75, Loss : nan\n",
      "Epoch 0, Step 76, Loss : nan\n",
      "Epoch 0, Step 77, Loss : nan\n",
      "Epoch 0, Step 78, Loss : nan\n",
      "Epoch 0, Step 79, Loss : nan\n",
      "Epoch 0, Step 80, Loss : nan\n",
      "Epoch 0, Step 81, Loss : nan\n",
      "Epoch 0, Step 82, Loss : nan\n",
      "Epoch 0, Step 83, Loss : nan\n",
      "Epoch 0, Step 84, Loss : nan\n",
      "Epoch 0, Step 85, Loss : nan\n",
      "Epoch 0, Step 86, Loss : nan\n",
      "Epoch 0, Step 87, Loss : nan\n",
      "Epoch 0, Step 88, Loss : nan\n",
      "Epoch 0, Step 89, Loss : nan\n",
      "Epoch 0, Step 90, Loss : nan\n",
      "Epoch 0, Step 91, Loss : nan\n",
      "Epoch 0, Step 92, Loss : nan\n",
      "Epoch 0, Step 93, Loss : nan\n",
      "Epoch 0, Step 94, Loss : nan\n",
      "Epoch 0, Step 95, Loss : nan\n",
      "Epoch 0, Step 96, Loss : nan\n",
      "Epoch 0, Step 97, Loss : nan\n",
      "Epoch 0, Step 98, Loss : nan\n",
      "Epoch 0, Step 99, Loss : nan\n",
      "Epoch 0, Step 100, Loss : nan\n",
      "Epoch 0, Step 101, Loss : nan\n",
      "Epoch 0, Step 102, Loss : nan\n",
      "Epoch 0, Step 103, Loss : nan\n",
      "Epoch 0, Step 104, Loss : nan\n",
      "Epoch 0, Step 105, Loss : nan\n",
      "Epoch 0, Step 106, Loss : nan\n",
      "Epoch 0, Step 107, Loss : nan\n",
      "Epoch 0, Step 108, Loss : nan\n",
      "Epoch 0, Step 109, Loss : nan\n",
      "Epoch 0, Step 110, Loss : nan\n",
      "Epoch 0, Step 111, Loss : nan\n",
      "Epoch 0, Step 112, Loss : nan\n",
      "Epoch 0, Step 113, Loss : nan\n",
      "Epoch 0, Step 114, Loss : nan\n",
      "Epoch 0, Step 115, Loss : nan\n",
      "Epoch 0, Step 116, Loss : nan\n",
      "Epoch 0, Step 117, Loss : nan\n",
      "Epoch 0, Step 118, Loss : nan\n",
      "Epoch 0, Step 119, Loss : nan\n",
      "Epoch 0, Step 120, Loss : nan\n",
      "Epoch 0, Step 121, Loss : nan\n",
      "Epoch 0, Step 122, Loss : nan\n",
      "Epoch 0, Step 123, Loss : nan\n",
      "Epoch 0, Step 124, Loss : nan\n",
      "Epoch 0, Step 125, Loss : nan\n",
      "Epoch 0, Step 126, Loss : nan\n",
      "Epoch 0, Step 127, Loss : nan\n",
      "Epoch 0, Step 128, Loss : nan\n",
      "Epoch 0, Step 129, Loss : nan\n",
      "Epoch 0, Step 130, Loss : nan\n",
      "Epoch 0, Step 131, Loss : nan\n",
      "Epoch 0, Step 132, Loss : nan\n",
      "Epoch 0, Step 133, Loss : nan\n",
      "Epoch 0, Step 134, Loss : nan\n",
      "Epoch 0, Step 135, Loss : nan\n",
      "Epoch 0, Step 136, Loss : nan\n",
      "Epoch 0, Step 137, Loss : nan\n",
      "Epoch 0, Step 138, Loss : nan\n",
      "Epoch 0, Step 139, Loss : nan\n",
      "Epoch 0, Step 140, Loss : nan\n",
      "Epoch 0, Step 141, Loss : nan\n",
      "Epoch 0, Step 142, Loss : nan\n",
      "Epoch 0, Step 143, Loss : nan\n",
      "Epoch 0, Step 144, Loss : nan\n",
      "Epoch 0, Step 145, Loss : nan\n",
      "Epoch 0, Step 146, Loss : nan\n",
      "Epoch 0, Step 147, Loss : nan\n",
      "Epoch 0, Step 148, Loss : nan\n",
      "Epoch 0, Step 149, Loss : nan\n",
      "Epoch 0, Step 150, Loss : nan\n",
      "Epoch 0, Step 151, Loss : nan\n",
      "Epoch 0, Step 152, Loss : nan\n",
      "Epoch 0, Step 153, Loss : nan\n",
      "Epoch 0, Step 154, Loss : nan\n",
      "Epoch 0, Step 155, Loss : nan\n",
      "Epoch 0, Step 156, Loss : nan\n",
      "Epoch 0, Step 157, Loss : nan\n",
      "Epoch 0, Step 158, Loss : nan\n",
      "Epoch 0, Step 159, Loss : nan\n",
      "Epoch 0, Step 160, Loss : nan\n",
      "Epoch 0, Step 161, Loss : nan\n",
      "Epoch 0, Step 162, Loss : nan\n",
      "Epoch 0, Step 163, Loss : nan\n",
      "Epoch 0, Step 164, Loss : nan\n",
      "Epoch 0, Step 165, Loss : nan\n",
      "Epoch 0, Step 166, Loss : nan\n",
      "Epoch 0, Step 167, Loss : nan\n",
      "Epoch 0, Step 168, Loss : nan\n",
      "Epoch 0, Step 169, Loss : nan\n",
      "Epoch 0, Step 170, Loss : nan\n",
      "Epoch 0, Step 171, Loss : nan\n",
      "Epoch 0, Step 172, Loss : nan\n",
      "Epoch 0, Step 173, Loss : nan\n",
      "Epoch 0, Step 174, Loss : nan\n",
      "Epoch 0, Step 175, Loss : nan\n",
      "Epoch 0, Step 176, Loss : nan\n",
      "Epoch 0, Step 177, Loss : nan\n",
      "Epoch 0, Step 178, Loss : nan\n",
      "Epoch 0, Step 179, Loss : nan\n",
      "Epoch 0, Step 180, Loss : nan\n",
      "Epoch 0, Step 181, Loss : nan\n",
      "Epoch 0, Step 182, Loss : nan\n",
      "Epoch 0, Step 183, Loss : nan\n",
      "Epoch 0, Step 184, Loss : nan\n",
      "Epoch 0, Step 185, Loss : nan\n",
      "Epoch 0, Step 186, Loss : nan\n",
      "Epoch 0, Step 187, Loss : nan\n",
      "Epoch 0, Step 188, Loss : nan\n",
      "Epoch 0, Step 189, Loss : nan\n",
      "Epoch 0, Step 190, Loss : nan\n",
      "Epoch 0, Step 191, Loss : nan\n",
      "Epoch 0, Step 192, Loss : nan\n",
      "Epoch 0, Step 193, Loss : nan\n",
      "Epoch 0, Step 194, Loss : nan\n",
      "Epoch 0, Step 195, Loss : nan\n",
      "Epoch 0, Step 196, Loss : nan\n",
      "Epoch 0, Step 197, Loss : nan\n",
      "Epoch 0, Step 198, Loss : nan\n",
      "Epoch 0, Step 199, Loss : nan\n",
      "Epoch 0, Step 200, Loss : nan\n",
      "Epoch 0, Step 201, Loss : nan\n",
      "Epoch 0, Step 202, Loss : nan\n",
      "Epoch 0, Step 203, Loss : nan\n",
      "Epoch 0, Step 204, Loss : nan\n",
      "Epoch 0, Step 205, Loss : nan\n",
      "Epoch 0, Step 206, Loss : nan\n",
      "Epoch 0, Step 207, Loss : nan\n",
      "Epoch 0, Step 208, Loss : nan\n",
      "Epoch 0, Step 209, Loss : nan\n",
      "Epoch 0, Step 210, Loss : nan\n",
      "Epoch 0, Step 211, Loss : nan\n",
      "Epoch 0, Step 212, Loss : nan\n",
      "Epoch 0, Step 213, Loss : nan\n",
      "Epoch 0, Step 214, Loss : nan\n",
      "Epoch 0, Step 215, Loss : nan\n",
      "Epoch 0, Step 216, Loss : nan\n",
      "Epoch 0, Step 217, Loss : nan\n",
      "Epoch 0, Step 218, Loss : nan\n",
      "Epoch 0, Step 219, Loss : nan\n",
      "Epoch 0, Step 220, Loss : nan\n",
      "Epoch 0, Step 221, Loss : nan\n",
      "Epoch 0, Step 222, Loss : nan\n",
      "Epoch 0, Step 223, Loss : nan\n",
      "Epoch 0, Step 224, Loss : nan\n",
      "Epoch 0, Step 225, Loss : nan\n",
      "Epoch 0, Step 226, Loss : nan\n",
      "Epoch 0, Step 227, Loss : nan\n",
      "Epoch 0, Step 228, Loss : nan\n",
      "Epoch 0, Step 229, Loss : nan\n",
      "Epoch 0, Step 230, Loss : nan\n",
      "Epoch 0, Step 231, Loss : nan\n",
      "Epoch 0, Step 232, Loss : nan\n",
      "Epoch 0, Step 233, Loss : nan\n",
      "Epoch 0, Step 234, Loss : nan\n",
      "Epoch 0, Step 235, Loss : nan\n",
      "Epoch 0, Step 236, Loss : nan\n",
      "Epoch 0, Step 237, Loss : nan\n",
      "Epoch 0, Step 238, Loss : nan\n",
      "Epoch 0, Step 239, Loss : nan\n",
      "Epoch 0, Step 240, Loss : nan\n",
      "Epoch 0, Step 241, Loss : nan\n",
      "Epoch 0, Step 242, Loss : nan\n",
      "Epoch 0, Step 243, Loss : nan\n",
      "Epoch 0, Step 244, Loss : nan\n",
      "Epoch 0, Step 245, Loss : nan\n",
      "Epoch 0, Step 246, Loss : nan\n",
      "Epoch 0, Step 247, Loss : nan\n",
      "Epoch 0, Step 248, Loss : nan\n",
      "Epoch 0, Step 249, Loss : nan\n",
      "Epoch 0, Step 250, Loss : nan\n",
      "Epoch 0, Step 251, Loss : nan\n",
      "Epoch 0, Step 252, Loss : nan\n",
      "Epoch 0, Step 253, Loss : nan\n",
      "Epoch 0, Step 254, Loss : nan\n",
      "Epoch 0, Step 255, Loss : nan\n",
      "Epoch 0, Step 256, Loss : nan\n",
      "Epoch 0, Step 257, Loss : nan\n",
      "Epoch 0, Step 258, Loss : nan\n",
      "Epoch 0, Step 259, Loss : nan\n",
      "Epoch 0, Step 260, Loss : nan\n",
      "Epoch 0, Step 261, Loss : nan\n",
      "Epoch 0, Step 262, Loss : nan\n",
      "Epoch 0, Step 263, Loss : nan\n",
      "Epoch 0, Step 264, Loss : nan\n",
      "Epoch 0, Step 265, Loss : nan\n",
      "Epoch 0, Step 266, Loss : nan\n",
      "Epoch 0, Step 267, Loss : nan\n",
      "Epoch 0, Step 268, Loss : nan\n",
      "Epoch 0, Step 269, Loss : nan\n",
      "Epoch 0, Step 270, Loss : nan\n",
      "Epoch 0, Step 271, Loss : nan\n",
      "Epoch 0, Step 272, Loss : nan\n",
      "Epoch 0, Step 273, Loss : nan\n",
      "Epoch 0, Step 274, Loss : nan\n",
      "Epoch 0, Step 275, Loss : nan\n",
      "Epoch 0, Step 276, Loss : nan\n",
      "Epoch 0, Step 277, Loss : nan\n",
      "Epoch 0, Step 278, Loss : nan\n",
      "Epoch 0, Step 279, Loss : nan\n",
      "Epoch 0, Step 280, Loss : nan\n",
      "Epoch 0, Step 281, Loss : nan\n",
      "Epoch 0, Step 282, Loss : nan\n",
      "Epoch 0, Step 283, Loss : nan\n",
      "Epoch 0, Step 284, Loss : nan\n",
      "Epoch 0, Step 285, Loss : nan\n",
      "Epoch 0, Step 286, Loss : nan\n",
      "Epoch 0, Step 287, Loss : nan\n",
      "Epoch 0, Step 288, Loss : nan\n",
      "Epoch 0, Step 289, Loss : nan\n",
      "Epoch 0, Step 290, Loss : nan\n",
      "Epoch 0, Step 291, Loss : nan\n",
      "Epoch 0, Step 292, Loss : nan\n",
      "Epoch 0, Step 293, Loss : nan\n",
      "Epoch 0, Step 294, Loss : nan\n",
      "Epoch 0, Step 295, Loss : nan\n",
      "Epoch 0, Step 296, Loss : nan\n",
      "Epoch 0, Step 297, Loss : nan\n",
      "Epoch 0, Step 298, Loss : nan\n",
      "Epoch 0, Step 299, Loss : nan\n",
      "Epoch 0, Step 300, Loss : nan\n",
      "Epoch 0, Step 301, Loss : nan\n",
      "Epoch 0, Step 302, Loss : nan\n",
      "Epoch 0, Step 303, Loss : nan\n",
      "Epoch 0, Step 304, Loss : nan\n",
      "Epoch 0, Step 305, Loss : nan\n",
      "Epoch 0, Step 306, Loss : nan\n",
      "Epoch 0, Step 307, Loss : nan\n",
      "Epoch 0, Step 308, Loss : nan\n",
      "Epoch 0, Step 309, Loss : nan\n",
      "Epoch 0, Step 310, Loss : nan\n",
      "Epoch 0, Step 311, Loss : nan\n",
      "Epoch 0, Step 312, Loss : nan\n",
      "Epoch 0, Step 313, Loss : nan\n",
      "Epoch 0, Step 314, Loss : nan\n",
      "Epoch 0, Step 315, Loss : nan\n",
      "Epoch 0, Step 316, Loss : nan\n",
      "Epoch 0, Step 317, Loss : nan\n",
      "Epoch 0, Step 318, Loss : nan\n",
      "Epoch 0, Step 319, Loss : nan\n",
      "Epoch 0, Step 320, Loss : nan\n",
      "Epoch 0, Step 321, Loss : nan\n",
      "Epoch 0, Step 322, Loss : nan\n",
      "Epoch 0, Step 323, Loss : nan\n",
      "Epoch 0, Step 324, Loss : nan\n",
      "Epoch 0, Step 325, Loss : nan\n",
      "Epoch 0, Step 326, Loss : nan\n",
      "Epoch 0, Step 327, Loss : nan\n",
      "Epoch 0, Step 328, Loss : nan\n",
      "Epoch 0, Step 329, Loss : nan\n",
      "Epoch 0, Step 330, Loss : nan\n",
      "Epoch 0, Step 331, Loss : nan\n",
      "Epoch 0, Step 332, Loss : nan\n",
      "Epoch 0, Step 333, Loss : nan\n",
      "Epoch 0, Step 334, Loss : nan\n",
      "Epoch 0, Step 335, Loss : nan\n",
      "Epoch 0, Step 336, Loss : nan\n",
      "Epoch 0, Step 337, Loss : nan\n",
      "Epoch 0, Step 338, Loss : nan\n",
      "Epoch 0, Step 339, Loss : nan\n",
      "Epoch 0, Step 340, Loss : nan\n",
      "Epoch 0, Step 341, Loss : nan\n",
      "Epoch 0, Step 342, Loss : nan\n",
      "Epoch 0, Step 343, Loss : nan\n",
      "Epoch 0, Step 344, Loss : nan\n",
      "Epoch 0, Step 345, Loss : nan\n",
      "Epoch 0, Step 346, Loss : nan\n",
      "Epoch 0, Step 347, Loss : nan\n",
      "Epoch 0, Step 348, Loss : nan\n",
      "Epoch 0, Step 349, Loss : nan\n",
      "Epoch 0, Step 350, Loss : nan\n",
      "Epoch 0, Step 351, Loss : nan\n",
      "Epoch 0, Step 352, Loss : nan\n",
      "Epoch 0, Step 353, Loss : nan\n",
      "Epoch 0, Step 354, Loss : nan\n",
      "Epoch 0, Step 355, Loss : nan\n",
      "Epoch 0, Step 356, Loss : nan\n",
      "Epoch 0, Step 357, Loss : nan\n",
      "Epoch 0, Step 358, Loss : nan\n",
      "Epoch 0, Step 359, Loss : nan\n",
      "Epoch 0, Step 360, Loss : nan\n",
      "Epoch 0, Step 361, Loss : nan\n",
      "Epoch 0, Step 362, Loss : nan\n",
      "Epoch 0, Step 363, Loss : nan\n",
      "Epoch 0, Step 364, Loss : nan\n",
      "Epoch 0, Step 365, Loss : nan\n",
      "Epoch 0, Step 366, Loss : nan\n",
      "Epoch 0, Step 367, Loss : nan\n",
      "Epoch 0, Step 368, Loss : nan\n",
      "Epoch 0, Step 369, Loss : nan\n",
      "Epoch 0, Step 370, Loss : nan\n",
      "Epoch 0, Step 371, Loss : nan\n",
      "Epoch 0, Step 372, Loss : nan\n",
      "Epoch 0, Step 373, Loss : nan\n",
      "Epoch 0, Step 374, Loss : nan\n",
      "Epoch 0, Step 375, Loss : nan\n",
      "Epoch 0, Step 376, Loss : nan\n",
      "Epoch 0, Step 377, Loss : nan\n",
      "Epoch 0, Step 378, Loss : nan\n",
      "Epoch 0, Step 379, Loss : nan\n",
      "Epoch 0, Step 380, Loss : nan\n",
      "Epoch 0, Step 381, Loss : nan\n",
      "Epoch 0, Step 382, Loss : nan\n",
      "Epoch 0, Step 383, Loss : nan\n",
      "Epoch 0, Step 384, Loss : nan\n",
      "Epoch 0, Step 385, Loss : nan\n",
      "Epoch 0, Step 386, Loss : nan\n",
      "Epoch 0, Step 387, Loss : nan\n",
      "Epoch 0, Step 388, Loss : nan\n",
      "Epoch 0, Step 389, Loss : nan\n",
      "Epoch 0, Step 390, Loss : nan\n",
      "Epoch 0, Step 391, Loss : nan\n",
      "Epoch 0, Step 392, Loss : nan\n",
      "Epoch 0, Step 393, Loss : nan\n",
      "Epoch 0, Step 394, Loss : nan\n",
      "Epoch 0, Step 395, Loss : nan\n",
      "Epoch 0, Step 396, Loss : nan\n",
      "Epoch 0, Step 397, Loss : nan\n",
      "Epoch 0, Step 398, Loss : nan\n",
      "Epoch 1, Step 0, Loss : nan\n",
      "Epoch 1, Step 1, Loss : nan\n",
      "Epoch 1, Step 2, Loss : nan\n",
      "Epoch 1, Step 3, Loss : nan\n",
      "Epoch 1, Step 4, Loss : nan\n",
      "Epoch 1, Step 5, Loss : nan\n",
      "Epoch 1, Step 6, Loss : nan\n",
      "Epoch 1, Step 7, Loss : nan\n",
      "Epoch 1, Step 8, Loss : nan\n",
      "Epoch 1, Step 9, Loss : nan\n",
      "Epoch 1, Step 10, Loss : nan\n",
      "Epoch 1, Step 11, Loss : nan\n",
      "Epoch 1, Step 12, Loss : nan\n",
      "Epoch 1, Step 13, Loss : nan\n",
      "Epoch 1, Step 14, Loss : nan\n",
      "Epoch 1, Step 15, Loss : nan\n",
      "Epoch 1, Step 16, Loss : nan\n",
      "Epoch 1, Step 17, Loss : nan\n",
      "Epoch 1, Step 18, Loss : nan\n",
      "Epoch 1, Step 19, Loss : nan\n",
      "Epoch 1, Step 20, Loss : nan\n",
      "Epoch 1, Step 21, Loss : nan\n",
      "Epoch 1, Step 22, Loss : nan\n",
      "Epoch 1, Step 23, Loss : nan\n",
      "Epoch 1, Step 24, Loss : nan\n",
      "Epoch 1, Step 25, Loss : nan\n",
      "Epoch 1, Step 26, Loss : nan\n",
      "Epoch 1, Step 27, Loss : nan\n",
      "Epoch 1, Step 28, Loss : nan\n",
      "Epoch 1, Step 29, Loss : nan\n",
      "Epoch 1, Step 30, Loss : nan\n",
      "Epoch 1, Step 31, Loss : nan\n",
      "Epoch 1, Step 32, Loss : nan\n",
      "Epoch 1, Step 33, Loss : nan\n",
      "Epoch 1, Step 34, Loss : nan\n",
      "Epoch 1, Step 35, Loss : nan\n",
      "Epoch 1, Step 36, Loss : nan\n",
      "Epoch 1, Step 37, Loss : nan\n",
      "Epoch 1, Step 38, Loss : nan\n",
      "Epoch 1, Step 39, Loss : nan\n",
      "Epoch 1, Step 40, Loss : nan\n",
      "Epoch 1, Step 41, Loss : nan\n",
      "Epoch 1, Step 42, Loss : nan\n",
      "Epoch 1, Step 43, Loss : nan\n",
      "Epoch 1, Step 44, Loss : nan\n",
      "Epoch 1, Step 45, Loss : nan\n",
      "Epoch 1, Step 46, Loss : nan\n",
      "Epoch 1, Step 47, Loss : nan\n",
      "Epoch 1, Step 48, Loss : nan\n",
      "Epoch 1, Step 49, Loss : nan\n",
      "Epoch 1, Step 50, Loss : nan\n",
      "Epoch 1, Step 51, Loss : nan\n",
      "Epoch 1, Step 52, Loss : nan\n",
      "Epoch 1, Step 53, Loss : nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-814635c949dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-10dfcf0355ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_data, training_targets, config)\u001b[0m\n\u001b[1;32m     32\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                             feed_dict={model.state_in[0] : lstm_state[0],\n\u001b[0;32m---> 34\u001b[0;31m                                       model.state_in[1] : lstm_state[1]})\n\u001b[0m\u001b[1;32m     35\u001b[0m                         print(\"Epoch {}, Step {}, Loss : {}\".format(\n\u001b[1;32m     36\u001b[0m                             \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config =  LSTM_Config()\n",
    "#feed = Data_Feed(signal_train, fail_train, config.batch_size, config.step_size)\n",
    "ct = 0\n",
    "\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(feed_test.init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            val = sess.run(feed_test.input_data)\n",
    "            print(val)\n",
    "            print(ct)\n",
    "            ct += 1\n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "            break\n",
    "\"\"\"\n",
    "train(signal_train, fail_train, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  6  3  4  2  3 10  6  8 11 11 11  2  9  7  3  8  7  4  4]\n",
      "[[ 3  6  3  4  2  3]\n",
      " [10  6  8 11 11 11]\n",
      " [ 2  9  7  3  8  7]]\n",
      "(3, 6)\n",
      "[[1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]\n",
      " [1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]\n",
      " [1.4690999 1.4690999 1.4690999 1.4690999 1.4690999 1.4690999]]\n"
     ]
    }
   ],
   "source": [
    "test = signal_train[0:20]\n",
    "y = fail_train[0:20]\n",
    "batch_size = 3\n",
    "step_size = 2\n",
    "\n",
    "data_len = len(test)\n",
    "batched_len = data_len // batch_size\n",
    "epoch_size = (batched_len-1) // step_size\n",
    "\n",
    "training_data = np.reshape(test[0:batched_len*batch_size],\n",
    "                          [batch_size, batched_len])\n",
    "training_label = np.reshape(y[0:batched_len*batch_size],\n",
    "                           [batch_size, batched_len])\n",
    "\n",
    "\n",
    "\n",
    "print(test)\n",
    "print(training_data)\n",
    "print(np.shape(training_data))\n",
    "print(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1, 20, 1)\n",
      "[[[ 3]\n",
      "  [ 6]\n",
      "  [ 3]\n",
      "  [ 4]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [10]\n",
      "  [ 6]\n",
      "  [ 8]\n",
      "  [11]\n",
      "  [11]\n",
      "  [11]\n",
      "  [ 2]\n",
      "  [ 9]\n",
      "  [ 7]\n",
      "  [ 3]\n",
      "  [ 8]\n",
      "  [ 7]\n",
      "  [ 4]\n",
      "  [ 4]]]\n"
     ]
    }
   ],
   "source": [
    "test = signal_train[0:20]\n",
    "num_periods = 20\n",
    "x_data = test[0:(len(test)-(len(test) % num_periods))]\n",
    "x_batches = x_data.reshape(-1,20,1)\n",
    "print(len(test) % num_periods)\n",
    "print(x_batches.shape)\n",
    "print(x_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorSliceDataset' object has no attribute 'window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-e0adc46fbcba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#data = data.apply(sliding.sliding_window_batch(window,stride))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msliding_window_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute 'window'"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.data.python.ops import sliding\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(training_data.T)\n",
    "targets = tf.data.Dataset.from_tensor_slices(training_label.T)\n",
    "window = 2\n",
    "stride = 1\n",
    "\n",
    "data = data.apply(sliding.sliding_window_batch(window,stride))\n",
    "targets = targets.apply(sliding.sliding_window_batch(window,stride))\n",
    "\n",
    "data_iterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\n",
    "target_iterator = tf.data.Iterator.from_structure(targets.output_types, targets.output_shapes)\n",
    "next_element = data_iterator.get_next()\n",
    "target_element = target_iterator.get_next()\n",
    "\n",
    "next_batch = tf.expand_dims(next_element,0)\n",
    "next_batch = tf.transpose(next_batch)\n",
    "next_targets = tf.expand_dims(target_element,0)\n",
    "next_targets = tf.transpose(next_targets)\n",
    "\n",
    "init_op = [data_iterator.make_initializer(data),target_iterator.make_initializer(targets)]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            batch = sess.run(next_batch)\n",
    "            tar = sess.run(next_targets)\n",
    "            print(batch)\n",
    "            print(tar)\n",
    "            print(np.shape(batch))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
